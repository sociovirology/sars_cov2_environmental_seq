# Script: analysis_figures.R
# This file is an R script that 
# NOTE: This file depends on XXXX Run that script first!

#This script is part of the following manuscript:
#"Environmental Surveillance for SARS-CoV-2 at the UC Davis Medical Center"
#David A. Coil | Timothy Albertson | Stuart H. Cohen | Satya Dandekar | Sam Diaz-Munoz | Jonathan A. Eisen | Tracey Goldstein | Maya Juarez | Brandt A Robinson | Christian Sandrock | Daniel G Tompkins | Alexandre Tremeau-Bravard | Angela Haczku

################ SARS-CoV-2 Hospital Environmental Sample Analyses ################
#### 1. Data Sources and Preparing Data
#### 2. Analysis of 
#### 3. Analysis of 

#THIS CODE NEEDS FOLOWING FILES: 
# .xls, 
# data/Temp_pH_Salinitt_for_B&C.csv,
# demultiplexing_by_sample.txt - This file generated by script minion_demultiplexing_flu_assignment.sh 
# avian_blast_matches.txt - This file generated by script minion_demultiplexing_flu_assignment.sh
# Individual sample *.out and *.tab files generated by script minion_demultiplexing_flu_assignment.sh 

#Project Description
#Analysis of MinION sequence data from water and sediment samples for avian influenza detection in California wetlands
#Code for "Linking remote sensing for targeted surveillance of Avian Influenza virus via tangential flow ultra-filtration and whole segment amplification in California wetlands"
#Collaboration between Diaz-Munoz Lab and Madeline McCuen, Maurice Pitesky (PI), UC Davis

#Load libraries
library(dplyr)
library(ggplot2)
library(readr)

#library(tidyr)
#library(ggthemes)
#library(gridExtra)
#library(reshape2)

#### 1. Data Sources and Preparing Data   ####
#Received spreadsheet UCDMC Swab Data.xlsx from David Coil via email on October 7, 2020 at 4:44pm, 
# subsequently downloaded extended, consolidated copy from GoogleDoc on Oct 27, 2020 at 4:27pm 
# Saved individual sheets as needed (described below) as CSV files from Excel to import to R

#Sheets Pilot "Goldsteinresults.csv" and "169 swabs" have sample and qPCR data for first and second round of hospital environmental sampling, respectively
#Importing below
first_round_sampling <- read.csv("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/sars_cov2_environmental_seq/data/Pilot Goldsteinresults.csv")
second_round_sampling <- read.csv("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/sars_cov2_environmental_seq/data/169 swabs.csv")

#Clean out unused columns and rows in each data frame
first_round_sampling <- first_round_sampling[2:61, 1:11] #Note also removing postive control row from data frame
second_round_sampling <- second_round_sampling[1:169, 1:22]

#Further cleaning: make column names match for the union of the data frames
colnames(first_round_sampling)
#[1] "Sample.number"                   "Location"                       
#[3] "Object.Surface"                  "Date.collected"                 
#[5] "CDC_N1Primer_SARS_CoV2_Ct"       "CDC_N2Primer_SARS_CoV2_Ct"      
#[7] "Berlin_RdRPPrimers_SARS_CoV2_Ct" "InternalHumanControl_RnaseP_Ct" 
#[9] "Quan"                            "Actin"                          
#[11] "Notes" 

#Strategy is to rename second_round_sampling data frame to match first
#Here focusing on the relevant qPCR results
colnames(second_round_sampling)[7:15] <- c("CDC_N1Primer_SARS_CoV2_Ct", "CDC_N1Primer_SARS_CoV2_Ct_Repeat", "CDC_N1Primer_SARS_CoV2_Ct_Positive", "CDC_N2Primer_SARS_CoV2_Ct", "CDC_N2Primer_SARS_CoV2_Ct_Repeat", "CDC_N2Primer_SARS_CoV2_Ct_Positive", "Berlin_RdRPPrimers_SARS_CoV2_Ct", "Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat", "Berlin_RdRPPrimers_SARS_CoV2_Ct_Positive")

#Sample.number column does not contain numbers in one of the data frames so changing first_round_sampling to factor so we can unite
first_round_sampling$Sample.number <- as.factor(first_round_sampling$Sample.number)

#Try to bind these two data frames, union all will keep matching and other columns 
sample_data <- union_all(first_round_sampling, second_round_sampling)
#Need to make columns the same so they align

#Quick visualization to check on qPCR values
ggplot(sample_data, aes(x = Sample.number, y = CDC_N1Primer_SARS_CoV2_Ct)) + 
  geom_point(position=position_jitter(width = .2, height = .05), size=3.5, alpha=0.75)

#First thing that pops up is the large number of undetermined samples and blank

#Let's clean up undetermined's now
sample_data$CDC_N1Primer_SARS_CoV2_Ct[grep("Undetermined", sample_data$CDC_N1Primer_SARS_CoV2_Ct)] <- NA
sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat[grep("Undetermined", sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat)] <- NA
sample_data$CDC_N2Primer_SARS_CoV2_Ct[grep("Undetermined", sample_data$CDC_N2Primer_SARS_CoV2_Ct)] <- NA
sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat[grep("Undetermined", sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat)] <- NA
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep("Undetermined", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)] <- NA
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat[grep("Undetermined", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat)] <- NA

#Now clean up blanks
sample_data$CDC_N1Primer_SARS_CoV2_Ct[grep("^$|^ $", sample_data$CDC_N1Primer_SARS_CoV2_Ct)] <- NA
sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat[grep("^$|^ $", sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat)] <- NA
sample_data$CDC_N2Primer_SARS_CoV2_Ct[grep("^$|^ $", sample_data$CDC_N2Primer_SARS_CoV2_Ct)] <- NA
sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat[grep("^$|^ $", sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat)] <- NA
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep("^$|^ $", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)] <- NA
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat[grep("^$|^ $", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat)] <- NA

#Now need to clean up some entries that are not numbers in Berlin RdRp primer
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep(")", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)]
#[1] "41.95(4-30-20)-und(5-6-20)"   "43.65(4-30-20)-43.72(5-6-20)"

#Ok, for the first one need to simply eliminate the parentheses and for second entry need to remove parentheses, take the average and replace
#These changes will be hard-coded to save time, but is documented here
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep("41.95", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)] <- 41.95
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep("43.65", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)] <- (43.65+43.72)/2
#Double check that it worked
(43.65+43.72)/2
#[1] 43.685
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct[grep("43.685", sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)]
#[1] "43.685"
#Looks good

#Now need to make sure all these columns are classified as numbers.
sample_data$CDC_N1Primer_SARS_CoV2_Ct <- as.numeric(sample_data$CDC_N1Primer_SARS_CoV2_Ct)
sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat <- as.numeric(as.character(sample_data$CDC_N1Primer_SARS_CoV2_Ct_Repeat)) #For some reason needed as.charcater so values wouldn't be rounded off
sample_data$CDC_N2Primer_SARS_CoV2_Ct <- as.numeric(sample_data$CDC_N2Primer_SARS_CoV2_Ct)
sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat <- as.numeric(as.character(sample_data$CDC_N2Primer_SARS_CoV2_Ct_Repeat)) #For some reason needed as.charcater so values wouldn't be rounded off
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct <- as.numeric(sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct)
sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat <- as.numeric(as.character(sample_data$Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat))

#Try again to plot to check
ggplot(sample_data, aes(x = Sample.number, y = CDC_N1Primer_SARS_CoV2_Ct)) + 
  geom_point(position=position_jitter(width = .2, height = .05), size=3.5, alpha=0.75)

#Now what we want to do is average the Ct values for a given sample
sample_data <- mutate(sample_data, mean_ct = rowMeans(cbind(CDC_N1Primer_SARS_CoV2_Ct, CDC_N1Primer_SARS_CoV2_Ct_Repeat, CDC_N2Primer_SARS_CoV2_Ct, CDC_N2Primer_SARS_CoV2_Ct_Repeat, Berlin_RdRPPrimers_SARS_CoV2_Ct, Berlin_RdRPPrimers_SARS_CoV2_Ct_Repeat), na.rm = TRUE))

#Fix NA's in the mean_ct column
sample_data$mean_ct <- gsub("NaN", NA, sample_data$mean_ct)

#Redraw graph 
ggplot(sample_data, aes(x = Sample.number, y = mean_ct)) + 
  geom_point(position=position_jitter(width = .2, height = .05), size=3.5, alpha=0.75) + coord_flip()

#Now data set is ready to add sequencing results
#First need to add barcode and sample information for each run

#Saved individual sheets as needed (described below) as CSV files from Excel (if not already CSV) to import to R
#Sam Díaz-Muñoz generated run_1_run2_barcodes.csv and run5_barcodes.csv manually based on lab notes for assigned barcodes
#Received two spreadsheets on Google Drive (Plate map.xlsx and Ct_values-ucdmc_samples.xlsx) from AJ Campbell via Diaz-Munoz Lab Slack on Nov 11, 2020 at 12:36pm 
# saved sheet AJs_run_3 in Plate map.xlsx as run3_barcodes.csv
# saved sheet AJs_run_4 in Ct_values-ucdmc_samples.xlsx as run4_barcodes.csv


#Import Run 1 and Run 2 sample/barcode information (note sample/barcodes combinations are identical in Run 1 and 2)
run_1_run2_barcodes <- read.csv("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/sars_cov2_environmental_seq/data/run_1_run2_barcodes.csv")

#Change NB01 and so on to barcode01, to interface with sequence data exported from bioinformatic analyses
run_1_run2_barcodes$barcode <- gsub("NB", "barcode", run_1_run2_barcodes$barcode)

#Import Run 3 and cleanup
run3_barcodes <- read_csv("data/run3_barcodes.csv", skip = 1)

#add barcode prefix to match sequecning results
run3_barcodes$Barcode[run3_barcodes$Barcode < 10] <- paste("barcode0", rep(1:9), sep = "")
run3_barcodes$Barcode[10:24] <- paste("barcode", run3_barcodes$Barcode[10:24], sep = "")

#Import Run 4 and cleanup
run4_barcodes <- read_csv("data/run4_barcodes.csv", trim_ws = TRUE, skip = 1)
#select relevant data
run4_barcodes <- run4_barcodes[1:11, c("Sample ID", "Barcode")]

#add barcode prefix to match sequencing results
run4_barcodes$Barcode[run4_barcodes$Barcode < 10] <- paste("barcode0", rep(1:9), sep = "")
run4_barcodes$Barcode[10:11] <- paste("barcode", run4_barcodes$Barcode[10:11], sep = "")

#Now need to fix the samples
run4_barcodes$`Sample ID` <- gsub("\\s*\\([^\\)]+\\)", "", run4_barcodes$`Sample ID`)
run4_barcodes$`Sample ID` <- gsub(" ", "", run4_barcodes$`Sample ID`)

#Import Run 5 and cleanup
run5_barcodes <- read_csv("data/run5_barcodes.csv")
#add barcode prefix to match sequecning results
run5_barcodes$barcode <- gsub("NB", "barcode", run5_barcodes$barcode)

#Ok, now we have to mash together the sample_barcode information for each df and add run information
#First let's add the run information to each df

#Make new data frame that has all run, barcode, and sample information
#First Runs 1 and 2
run_sample_barcode <- rbind(run_1_run2_barcodes, run_1_run2_barcodes)
#Add run information
run <- c(rep("run1", nrow(run_1_run2_barcodes)), rep("run2", nrow(run_1_run2_barcodes)))
#Bind
run_sample_barcode <- cbind(run_sample_barcode, run)

#Now Runs 3 and 4

#First bind into new larger data frame
run3_run4_barcodes <- rbind(run3_barcodes[2:3], run4_barcodes)

#rearrange column order
run3_run4_barcodes <- data.frame(run3_run4_barcodes$Barcode, run3_run4_barcodes$`Sample ID`)

#Then add run information
run <- c(rep("run3", nrow(run3_barcodes)), rep("run4", nrow(run4_barcodes)))
run3_run4_barcodes <- cbind(run3_run4_barcodes, run)

#Make columns identical to run_sample_barcode data frame
colnames(run3_run4_barcodes) <- colnames(run_sample_barcode)

#Add to run_sample_barcode data frame
run_sample_barcode <- rbind(run_sample_barcode, run3_run4_barcodes)

#Finally let's add run5
#Just add run information
run <- rep("run5", nrow(run5_barcodes))
run5_barcodes <- cbind(run5_barcodes, run)

#Add run5 df to run_sample_barcode data frame
run_sample_barcode <- rbind(run_sample_barcode, run5_barcodes)

#Finally let's add a run_barcode field we will use to interface with coverage data
run_sample_barcode <- data.frame(run_sample_barcode, run_barcode = paste(run_sample_barcode$run, run_sample_barcode$barcode, sep = "_"))
#Perfect

#Now we can input the sample data, do a join with the sample_data data frame
#First need to change the sample column
colnames(sample_data)[1] <- c("sample")

#Now subset the data frame for the things we want to join
sample_data_subset <- sample_data[c("sample", "Location", "Object.Surface", "Date.collected", "mean_ct")]

#Now let's join with the run_sample_barcode data
master_df <- left_join(run_sample_barcode, sample_data_subset, by="sample")

#We will append the sequencing results to this data frame, but first need to import uncalled bases

#Import sequencing results, specifically a list of the number of N's (undefined bases) to calculate percent coverage
uncalled_bases <- read_csv("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/uncalled_bases.csv", col_names = FALSE)
#Label columns
colnames(uncalled_bases) <- c("run_barcode", "uncalled_bases", "minimum_fold_coverage")
#Remove X from coverage column
uncalled_bases$minimum_fold_coverage <- gsub("X", "", uncalled_bases$minimum_fold_coverage)

#Generate a column with called bases
uncalled_bases <- mutate(uncalled_bases, called_bases = (29902-uncalled_bases))

#Generate a column with percent called bases
uncalled_bases <- mutate(uncalled_bases, percent_called = (called_bases/29902*100))

#Coverage 
ggplot(subset(uncalled_bases, subset = percent_called > 1 & minimum_fold_coverage == 5), aes(x = run_barcode, y = percent_called)) + 
  geom_point(aes(reorder(run_barcode, percent_called, mean)), position=position_jitter(width = .2, height = .05), size=3.5, alpha=0.75) + coord_flip()

#IMPORTANT: JUSTIFY THE 5X cutoff with code
uncalled_bases_5X <- subset(uncalled_bases, minimum_fold_coverage == 5)

#Now join uncalled base data
master_df <- left_join(master_df, uncalled_bases_5X, by="run_barcode")

#### 2. Analysis of Collected Samples ####

#Sequencing Stats:
#Total reads per run
#Total mapped reads
#Reads per barcode/sample
#Coverage
#Percent divergence from reference

#Number of reads maped vs. Ct score

#Coverage vs. Ct Score
#IMPORTANT: JUSTIFY THE 5X cutoff with code
uncalled_bases_5X <- subset(uncalled_bases, minimum_fold_coverage == 5)

#Now join uncalled base data
master_df <- left_join(master_df, uncalled_bases_5X, by="run_barcode")

#Graph!
#Subsetting to include only samples with Ct scores, thus controls not included here (no need to remove). 
# However, some samples are repeats in different runs 
ggplot(subset(master_df, !is.na(mean_ct)), aes(x = as.numeric(mean_ct), y = percent_called, color = sample)) + 
  geom_point(position=position_jitter(width = .05, height = .05), size=3.5, alpha=0.75) + theme(legend.position="none") +
  xlab("Mean Ct Value from RT-qPCR") + ylab("Percent of Genome Sequenced at ≥ 5X")


#Summary statistics for percentage coverage. Means and medians won't describe data well, because lots of zeros
#Let's visualize data to check an appraoch

#Quick histogram to view the data. 
ggplot(subset(master_df, !is.na(mean_ct)), aes(x = percent_called)) + geom_histogram()
#Looks like three groups

#Groups can also can be viewed in ordered point plot
ggplot(subset(master_df, percent_called > 1), aes(x = sample, y = percent_called)) + 
  geom_point(aes(reorder(run_barcode, percent_called, mean)), position=position_jitter(width = .2, height = .05), size=3.5, alpha=0.75) + coord_flip()

#Defining three groups of percentage coverage, based on graphs. Note these have repeat samples (e.g. sample 8 run twice)
#Less than 15% total bases called
nrow(subset(master_df, percent_called < 15))
#[1] 75

#Between 20-40% total bases called
nrow(subset(master_df, percent_called > 20 & percent_called < 40))
#[1] 5

#Over 75% total bases called
nrow(subset(master_df, percent_called > 75))
#[1] 5

#Detection of SARS-CoV-2 via ARTIC Protocol Sequencing vs. RT-qPCR

#If we were to use PCR/sequencing as a detection method and compare to RT-qPCR how much better would we do?

#First need to remove the positive and negative controls:
#Check grep expressions
grep("ENV", master_df$sample, value = TRUE)
grep("^[0-9]", master_df$sample, value = TRUE)

#Now select from data frame and make a new sample only dataframe
samples_only_master <- rbind(master_df[grep("^[0-9]", master_df$sample), ], master_df[grep("ENV", master_df$sample), ])

#Total samples
nrow(samples_only_master)
#[1] 74

#Now check the number of samples that have a Ct score
nrow(subset(samples_only_master, mean_ct > 0)) 
#[1] 23

#"Success" rate of RT-qPCR
nrow(subset(samples_only_master, mean_ct > 0)) / nrow(samples_only_master)
#[1] 0.3108108

#Now let's look at the sequecing, using percentage coverage 
#First have to decide on a cutoff. Conservatively can pick >2%. This would be ~600bp that are specifically mapped, compared to a 100bp amplicon that is not sequenced

#Number of samples
nrow(subset(samples_only_master, percent_called > 2))
#32

#"Success" rate
nrow(subset(samples_only_master, percent_called > 2)) / nrow(samples_only_master)
#0.4459459

#Larger, but not by much. Let's test statistically
#Now we conduct proportion test with numbers above 
prop.test(c(23, 32), c(74, 74), correct=T)
#2-sample test for equality of proportions with continuity correction
#data:  c(23, 32) out of c(74, 74)
#X-squared = 1.8518, df = 1, p-value = 0.1736
#alternative hypothesis: two.sided
#95 percent confidence interval:
#  -0.28960441  0.04636117
#sample estimates:
#  prop 1    prop 2 
#0.3108108 0.4324324 
#Difference is not statistically significant. 

#Another way to look at this is to look at the samples missed by RT-qPCR

#Number of samples with a Ct score and coverage of > 2%
nrow(subset(samples_only_master, percent_called > 2 & mean_ct > 0))
#[1] 17

#Number of samples with no Ct score and coverage of > 2%
nrow(subset(samples_only_master, percent_called > 2 & is.na(mean_ct)))
#[1] 15

#Detection nearly doubles if using sequencing as indicator!

#### 3. Sequencing Depth Analysis of Near-Complete Genomes  ####
#First we'll look at which samples we want to generate plots for
subset(master_df, percent_called > 90, select = c("barcode", "sample", "run_barcode", "percent_called"))
#     barcode sample    run_barcode percent_called
#5  barcode05     27 run1_barcode05       96.30794
#29 barcode05     27 run2_barcode05       99.01679
#42 barcode18     51 run2_barcode18       91.74637
#93 barcode10     27 run5_barcode10       93.70611

#Of these we'll choose the Run 2 samples (more reads, more complete) for sample 27 and 51
# These will be identified by their barcode numbers in the run folder, like so: 
# barcode0*/sample_barcode0*.coverage_mask.txt.nCoV-2019_1.depths
# barcode0*/sample_barcode0*.coverage_mask.txt.nCoV-2019_2.depths
# that is, the ARTIC pipeline outputs separate files for Pool 1 and Pool 2 primers
# We wil merge those files and generate graphs for them

#Import Pool coverages from barcode05 in Run 1
run1_barcode05_pool_1 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run1/barcode05/sample_barcode05.coverage_mask.txt.nCoV-2019_1.depths", header=FALSE)
#Import pool 2 coverages
run1_barcode05_pool_2 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run1/barcode05/sample_barcode05.coverage_mask.txt.nCoV-2019_2.depths", header=FALSE)

#Import Pool coverages from barcode18 in Run 1
run1_barcode18_pool_1 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run1/barcode18/sample_barcode18.coverage_mask.txt.nCoV-2019_1.depths", header=FALSE)
#Import pool 2 coverages
run1_barcode18_pool_2 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run1/barcode18/sample_barcode18.coverage_mask.txt.nCoV-2019_2.depths", header=FALSE)

#Import Pool coverages from barcode05 in Run 2
run2_barcode05_pool_1 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run2/barcode05/sample_barcode05.coverage_mask.txt.nCoV-2019_1.depths", header=FALSE)
#Import pool 2 coverages
run2_barcode05_pool_2 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run2/barcode05/sample_barcode05.coverage_mask.txt.nCoV-2019_2.depths", header=FALSE)

#Import Pool coverages from barcode18 in Run 2
run2_barcode18_pool_1 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run2/barcode18/sample_barcode18.coverage_mask.txt.nCoV-2019_1.depths", header=FALSE)
#Import pool 2 coverages
run2_barcode18_pool_2 <- read.delim("~/Dropbox/mixtup/Documentos/ucdavis/papers/covid19_environmental/run_pipeline_outputs/ncov_ucdh_env1_run2/barcode18/sample_barcode18.coverage_mask.txt.nCoV-2019_2.depths", header=FALSE)


generate_depth_plot <- function(pool1, pool2) { 
  #input are two dataframes imported from ARTIC network output files: barcode0*/sample_barcode0*.coverage_mask.txt.nCoV-2019_1.depths 
  #Adjust colnames
  colnames(pool1) <- c("reference", "pool", "position", "depth")
  
  #Adjust colnames
  colnames(pool2) <- c("reference", "pool", "position", "depth")
  
  #Now rearrange to get both depths from both pools in one data frame
  depth <- pool1
  
  #Adjust colnames
  colnames(depth) <- c("reference", "pool", "position", "depth_pool1")
  
  #Make a depth data frame
  depth <- cbind(depth, pool2$depth)
  
  #Rename columns
  colnames(depth) <- c("reference", "pool", "position", "depth_pool1", "depth_pool2")
  
  #Add up pool depths to 
  depth <- mutate(depth, depth = depth_pool1 + depth_pool2)
  
  ggplot(depth, aes(x = position, y = depth)) + 
    geom_bar(stat = "identity")  
}

#Generated a function, let's see if it works
run2_barcode05_depth <- generate_depth_plot(run2_barcode05_pool_1, run2_barcode05_pool_2)
run1_barcode05_depth <- generate_depth_plot(run1_barcode05_pool_1, run1_barcode05_pool_2)
#Ok! Proceed with the other samples

run2_barcode18_depth <- generate_depth_plot(run2_barcode18_pool_1, run2_barcode18_pool_2)
run1_barcode18_depth <- generate_depth_plot(run1_barcode18_pool_1, run1_barcode18_pool_2)

#Now generate some individual stats for each one 
mean(depth$depth)
#[1] 429.9383

sd(depth$depth)
#[1] 147.0732

#Percent with 0 coverage
nrow(subset(depth, depth == 0)) / length(depth$position)
#[1] 0.009764907

#Number of positions with coverage <1X
nrow(subset(depth, depth < 1))
#[1] 292

#Percent with <5X coverage
nrow(subset(depth, depth < 5)) / length(depth$position)
#[1] 0.009764907

#Number of positions with <5X coverage
nrow(subset(coverage, depth < 5))
#[1] 2031

#Number of positions with <20X coverage
nrow(subset(coverage, depth < 20))
#[1] 4279

ggplot(depth, aes(x = position, y = depth)) + 
  geom_bar(stat = "identity")